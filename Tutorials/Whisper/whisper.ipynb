{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial you will learn how to use Whisper to transcribe text from audio files as well translate it into English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you **haven't set up your OpenAI API key** as a global system variable you can set it up now by pasting it into the **.env** file and running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, just runs this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the audio file**\n",
    "\n",
    "Feel free to try different audio files as well as add/record your own. Files must be of one of these types: mp3, mp4, mpeg, mpga, m4a, wav, and webm.\n",
    "\n",
    "**Note that files greater than 25MB will need to be segmented using [additional libraries](https://platform.openai.com/docs/guides/speech-to-text/longer-inputs).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file= open(\"audio.wav\", \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - Transcribe an audio file**\n",
    "\n",
    "The transcription endpoint will take the input audio and transcribe it into text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amor é um fogo que arde sem se ver. É a ferida que dói e não se sente. É um contentamento descontente. É dor que desatina sem doer. É um não querer mais que bem querer. É solitário andar por entre a gente. É um não contentar-se de contente. É cuidar que se ganha em se perder. É um estar-se preso por vontade. É servir a quem vence, o vencedor. É ter com quem nos mata, lealdade. Mas como causar pode o seu favor nos mortais corações conformidade, sendo a si tão contrário o mesmo amor?\n",
      "\n"
<<<<<<< HEAD
=======
     ]
    }
   ],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    response_format=\"text\"\n",
    ")\n",
    "\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how **response_format=\"text\"**? To get additional information to get additional information try changing it to **verbose_json**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now receive a json response with additional parameters. One of which, the **\"language\"** parameter, includes the detected language from the input file.\n",
    "\n",
    "**Note:** If the language is not being properly detected, which may negatively impact transcription, you can add an additional parameter stating it according to the \n",
    "[ISO-639-1 format](https://en.wikipedia.org/wiki/List_of_ISO_639_language_codes)\n",
    "```\n",
    "language=\"...\"\n",
    "```\n",
    "\n",
    "We can modify our code to reflect this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: portuguese\n",
      "Amor é um fogo que arde sem se ver. É a ferida que dói e não se sente. É um contentamento descontente. É dor que desatina sem doer. É um não querer mais que bem querer. É solitário andar por entre a gente. É um não contentar-se de contente. É cuidar que se ganha em se perder. É um estar-se preso por vontade. É servir a quem vence, o vencedor. É ter com quem nos mata, lealdade. Mas como causar pode o seu favor nos mortais corações conformidade, sendo a si tão contrário o mesmo amor?\n"
>>>>>>> f82140d (update notebook with completed transcription and translation tutorial.)
     ]
    }
   ],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
<<<<<<< HEAD
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    response_format=\"text\"\n",
    ")\n",
    "\n",
    "print(transcription)"
=======
    "    model=\"whisper-1\", \n",
    "    file=audio_file,\n",
    "    response_format=\"verbose_json\"\n",
    ")\n",
    "\n",
    "print(f\"Detected language: {transcription.language}\")\n",
    "print(transcription.text)"
>>>>>>> f82140d (update notebook with completed transcription and translation tutorial.)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Notice how **response_format=\"text\"**? To get additional information to get additional information try changing it to **verbose_json**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should that you now receive a json response with additional parameters. One of which, the **\"language\"** parameter, includes the detected language from the input file.\n",
    "\n",
    "We can modify our code to reflect this:"
=======
    "**2 - Translation**\n",
    "\n",
    "Using the translation endpoint we can translate the contents of the audio file to English (currently this the only available language for translation)."
>>>>>>> f82140d (update notebook with completed transcription and translation tutorial.)
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file,\n",
    "    response_format=\"verbose_json\"\n",
    ")\n",
    "print(f\"Detected language: {transcription.language}\")\n",
    "print(transcription.text)"
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love is a fire that burns without being seen. It's a wound that hurts and you don't feel it. It's a discontented contentment. It's pain that goes unhealed without pain. It's not wanting more than wanting well. It's lonely to walk among people. It's not being contented with contentment. It's taking care that you win instead of losing yourself. It's being trapped by will. It's serving those who win, the winner. It's having loyalty with those who kill us. But how can you cause your favor in the hearts of mortals with firmness being so contrary to the same love?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "translation = client.audio.translations.create(\n",
    "    model = \"whisper-1\", \n",
    "    file = audio_file,\n",
    "    response_format=\"text\"\n",
    ")\n",
    "\n",
    "print(translation)"
>>>>>>> f82140d (update notebook with completed transcription and translation tutorial.)
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
