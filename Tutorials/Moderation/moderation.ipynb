{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moderation\n",
    "The moderation endpoint is a tool you can use to check whether text is potentially harmful. It can be used to identify content that could be harmful and take action.\n",
    "\n",
    "The templates classify the following categories:\n",
    "* `Hate` - Content that expresses or promotes hatred based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status or caste. Hateful content directed at unprotected groups constitutes harassment.\n",
    "* `Hate/Threatening` - Hateful content that also includes violence or serious harm towards the targeted group based on race, gender, ethnicity, religion, nationality, sexual orientation, disability status, or caste.\n",
    "* `Harassment` - Content that expresses, incites, or promotes harassing language towards any target.\n",
    "* `Harassment/Threatening` - Harassment content that also includes violence or serious harm towards any target.\n",
    "* `Self-harm` - Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders.\n",
    "* `Self-harm/Intent` - Content where the speaker expresses that they are engaging or intend to engage in acts of self-harm, such as suicide, cutting, and eating disorders.\n",
    "* `Self-harm/Instructions` - Content that encourages performing acts of self-harm, such as suicide, cutting, and eating disorders, or that gives instructions or advice on how to commit such acts.\n",
    "* `Sexual` - Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness).\n",
    "* `Sexual/Minors` - Sexual content that includes an individual who is under 18 years old.\n",
    "* `Violence` - Content that depicts death, violence, or physical injury.\n",
    "* `Violence/Graphic` - Content that depicts death, violence, or physical injury in graphic detail.\n",
    "\n",
    "\n",
    "To obtain a classification for a piece of text, a request is made to the moderation endpoint, as shown in the following code fragment.\n",
    "Firstly, the OpenAI class from the openai module is imported, then an instance of the class is created and assigned to a variable, configuring the client to interact with the OpenAI API.\n",
    "\n",
    "With the `moderations.create()` method, the text is sent for moderation.\n",
    "\n",
    "The response from the API will be a JSON object with information about the moderation of the text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=True, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_scores=CategoryScores(harassment=0.0047630504705011845, harassment_threatening=0.004998649470508099, hate=0.0028446433134377003, hate_threatening=7.896835450083017e-05, self_harm=0.0002955093514174223, self_harm_instructions=1.0710728304275108e-07, self_harm_intent=9.992040577344596e-05, sexual=1.5535953934886493e-05, sexual_minors=2.3286467865091254e-07, violence=0.9116463661193848, violence_graphic=0.0004263202426955104, self-harm=0.0002955093514174223, sexual/minors=2.3286467865091254e-07, hate/threatening=7.896835450083017e-05, violence/graphic=0.0004263202426955104, self-harm/intent=9.992040577344596e-05, self-harm/instructions=1.0710728304275108e-07, harassment/threatening=0.004998649470508099), flagged=True)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.moderations.create(input=\"I own a lot of guns which I intend to use, in order to harm people.\")\n",
    "\n",
    "output = response.results[0]\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the endpoint response structure. It returns the following fields:\n",
    "\n",
    "* `flagged`: Set to true if the model classifies the content as potentially harmful, false otherwise.\n",
    "\n",
    "* `categories`: Contains a dictionary of violation flags for each category. The value will be true if the model flags the corresponding category as violated, false otherwise.\n",
    "* `category_scores`: Contains a dictionary of raw scores per category issued by the model, denoting the model's confidence that the input violates the OpenAI policy for the category. The value is between 0 and 1, with higher values denoting greater confidence. The scores should not be interpreted as probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` json\n",
    "{\n",
    "    \n",
    "    \"id\": \"modr-XXXXX\",\n",
    "    \"model\": \"text-moderation-007\",\n",
    "    \"results\": [\n",
    "        {\n",
    "            \"flagged\": true,\n",
    "            \"categories\": {\n",
    "                \"sexual\": false,\n",
    "                \"hate\": false,\n",
    "                \"harassment\": false,\n",
    "                \"self-harm\": false,\n",
    "                \"sexual/minors\": false,\n",
    "                \"hate/threatening\": false,\n",
    "                \"violence/graphic\": false,\n",
    "                \"self-harm/intent\": false,\n",
    "                \"self-harm/instructions\": false,\n",
    "                \"harassment/threatening\": true,\n",
    "                \"violence\": true\n",
    "            },\n",
    "            \"category_scores\": {\n",
    "                \"sexual\": 1.2282071e-6,\n",
    "                \"hate\": 0.010696256,\n",
    "                \"harassment\": 0.29842457,\n",
    "                \"self-harm\": 1.5236925e-8,\n",
    "                \"sexual/minors\": 5.7246268e-8,\n",
    "                \"hate/threatening\": 0.0060676364,\n",
    "                \"violence/graphic\": 4.435014e-6,\n",
    "                \"self-harm/intent\": 8.098441e-10,\n",
    "                \"self-harm/instructions\": 2.8498655e-11,\n",
    "                \"harassment/threatening\": 0.63055265,\n",
    "                \"violence\": 0.99011886\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
