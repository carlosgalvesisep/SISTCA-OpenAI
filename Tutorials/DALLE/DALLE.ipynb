{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Image Generation (DALL-E)\n",
    "\n",
    "\n",
    "\n",
    "The open AI image API provides three methods for interacting with images, namely creating images from scratch using a text prompt (DALL-E 3 and DALL-E 2), creating edited versions of images by having the model change some areas of a pre-existing image based on a new text prompt (DALL-E 2 only) and creating variations of an existing image (DALL-E 2 only).\n",
    "\n",
    "This guide covers the basics of the API methods with useful code examples. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Image Generation \n",
    "\n",
    "The image generation method allows you to create an original image with a text prompt.\n",
    "\n",
    "Initially, it is necessary to import the display and Image functions from the IPython.display module, in order to display the image inside a Jupyter notebook.\n",
    "\n",
    "It also imports os, used for operating system operations, as explained earlier for creating a venv environment, and imports the OpenAI class from the openai module, an interface for using the API.\n",
    "\n",
    "The code creates an instance of the OpenAI() client.\n",
    "A request is made to the API to generate an image, with the parameters:\n",
    "\n",
    "* __model :__ specifies the model used to generate the image, in this case \"dall-e-2\", which specialises in generating images based on textual descriptions;\n",
    "* __prompt :__ descriptive text that will serve as input for the model to generate the image, in this example, \"A cat inside a car\";\n",
    "* __size :__ specifies the size, 1024x1024 pixels;\n",
    "* __quality :__  sets the quality, \"standard\". When using DALL-E 3 it is possible to set quality: \"hd\", i.e. fine detail. However, standard quality square images are generated more quickly;\n",
    "* __n :__ defines the number of images generated.\n",
    "\n",
    "After the API generates the image, the image URL is extracted from the response and stored in the image_url variable.\n",
    "Finally, the image URL is printed and the image is displayed using the display function with the Image class, passing the URL as a parameter and setting the image width to 500 pixels.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-WBkw2zo1WHpT09Ib6xAN0sL0/user-n6ilnWbPionjiMJDmHYLi7un/img-G1mOTMWx8ag37oX1J2hbCAYp.png?st=2024-05-15T10%3A01%3A24Z&se=2024-05-15T12%3A01%3A24Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-14T16%3A32%3A35Z&ske=2024-05-15T16%3A32%3A35Z&sks=b&skv=2021-08-06&sig=0lCZaBHYyZV6XhiLYPAbvLSJeSXB5xjdrBVye0TogwY%3D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-WBkw2zo1WHpT09Ib6xAN0sL0/user-n6ilnWbPionjiMJDmHYLi7un/img-G1mOTMWx8ag37oX1J2hbCAYp.png?st=2024-05-15T10%3A01%3A24Z&se=2024-05-15T12%3A01%3A24Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-14T16%3A32%3A35Z&ske=2024-05-15T16%3A32%3A35Z&sks=b&skv=2021-08-06&sig=0lCZaBHYyZV6XhiLYPAbvLSJeSXB5xjdrBVye0TogwY%3D\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-2\",\n",
    "  prompt=\"A cat inside a car\",\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "print(image_url)\n",
    "display(Image(url=image_url, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2 Edits (DALLE 2 only)\n",
    "\n",
    "Also known as \"inpainting\", the image editing endpoint allows you to edit an image by loading an image and a mask indicating the areas that should be replaced, you can use tools such as [GIMP](https://www.gimp.org/) or [Photoshop](https://www.adobe.com/pt/products/photoshop/landpa.html?gclid=CjwKCAjw57exBhAsEiwAaIxaZrgKDCM6FAEGOCavdUMdwMkJnL6o9cWGXjdYdjYN1DoN5HeWLj6-nBoCTjgQAvD_BwE&mv=search&s_kwcid=AL!3085!3!340859421278!e!!g!!adobe%20photoshop!1447265685!53212492301&mv=search&mv2=paidsearch&sdid=2XBSBWBF&ef_id=CjwKCAjw57exBhAsEiwAaIxaZrgKDCM6FAEGOCavdUMdwMkJnL6o9cWGXjdYdjYN1DoN5HeWLj6-nBoCTjgQAvD_BwE:G:s&s_kwcid=AL!3085!3!340859421278!e!!g!!adobe%20photoshop!1447265685!53212492301&gad_source=1), to erase a certain area of the image. \n",
    "The transparent areas of the mask indicate where the image should be edited, and the prompt should describe the complete new image, not just the deleted area.\n",
    "\n",
    "The image and mask sent must be square PNG images of less than 4 MB and must also have the same dimensions. The non-transparent areas of the mask are not used to generate the output, so they don't necessarily have to match the original image as in the following example, which shows the original image, the mask and the resulting image after the editing process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"pt\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "<title>Imagens</title>\n",
    "<style>\n",
    "    figure {\n",
    "        float: left;\n",
    "        margin-right: 20px; /* Espaçamento entre as imagens */\n",
    "    }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<figure>\n",
    "    <img src=\"original.png\" width=\"350\" height=\"350\" alt=\"\">\n",
    "    <figcaption>Original</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"mask.png\" width=\"350\" height=\"350\" alt=\"\">\n",
    "    <figcaption>Mask</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"output.png\" width=\"350\" height=\"350\" alt=\"\">\n",
    "    <figcaption>Output</figcaption>\n",
    "</figure>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-WBkw2zo1WHpT09Ib6xAN0sL0/user-n6ilnWbPionjiMJDmHYLi7un/img-25glpQQ2Zmjx0RJXtRaKQOVS.png?st=2024-05-16T18%3A27%3A57Z&se=2024-05-16T20%3A27%3A57Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-16T16%3A16%3A05Z&ske=2024-05-17T16%3A16%3A05Z&sks=b&skv=2021-08-06&sig=1%2BL/rgk38cK9sBsVBuDDguX7d4RWrnGKlHuXKvDiAxc%3D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-WBkw2zo1WHpT09Ib6xAN0sL0/user-n6ilnWbPionjiMJDmHYLi7un/img-25glpQQ2Zmjx0RJXtRaKQOVS.png?st=2024-05-16T18%3A27%3A57Z&se=2024-05-16T20%3A27%3A57Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-16T16%3A16%3A05Z&ske=2024-05-17T16%3A16%3A05Z&sks=b&skv=2021-08-06&sig=1%2BL/rgk38cK9sBsVBuDDguX7d4RWrnGKlHuXKvDiAxc%3D\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "from IPython.display import display, Image\n",
    "\n",
    "response = client.images.edit(\n",
    "  model=\"dall-e-2\",\n",
    "  image=open(\"original.png\", \"rb\"),\n",
    "  mask=open(\"mask.png\", \"rb\"),\n",
    "  prompt=\"A hand holding a sandwich\",\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "image_url = response.data[0].url\n",
    "\n",
    "print(image_url)\n",
    "display(Image(url=image_url, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 Variations (DALL·E 2 only)\n",
    "\n",
    "The image variations endpoint allows you to generate a variation of a given image.\n",
    "\n",
    "Similar to the edits endpoint, the input image must be a square PNG image less than 4MB in size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-WBkw2zo1WHpT09Ib6xAN0sL0/user-n6ilnWbPionjiMJDmHYLi7un/img-q3z96usbuzFtDQLYGg1w4BRs.png?st=2024-05-15T10%3A06%3A51Z&se=2024-05-15T12%3A06%3A51Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-14T16%3A08%3A49Z&ske=2024-05-15T16%3A08%3A49Z&sks=b&skv=2021-08-06&sig=1nFU627eyWnkhOyECyjDPHykN2QnH/ZtEvR9BXsLVOA%3D\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-WBkw2zo1WHpT09Ib6xAN0sL0/user-n6ilnWbPionjiMJDmHYLi7un/img-q3z96usbuzFtDQLYGg1w4BRs.png?st=2024-05-15T10%3A06%3A51Z&se=2024-05-15T12%3A06%3A51Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-05-14T16%3A08%3A49Z&ske=2024-05-15T16%3A08%3A49Z&sks=b&skv=2021-08-06&sig=1nFU627eyWnkhOyECyjDPHykN2QnH/ZtEvR9BXsLVOA%3D\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.images.create_variation(\n",
    "  model=\"dall-e-2\",\n",
    "  image=open(\"original.png\", \"rb\"),\n",
    "  n=1,\n",
    "  size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "\n",
    "print(image_url)\n",
    "display(Image(url=image_url, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images below correspond to a possible example of the endpoint variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"pt\">\n",
    "<head>\n",
    "<meta charset=\"UTF-8\">\n",
    "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "<title>Imagens</title>\n",
    "<style>\n",
    "    figure {\n",
    "        float: left;\n",
    "        margin-right: 20px; /* Espaçamento entre as imagens */\n",
    "    }\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "<figure>\n",
    "    <img src=\"original.png\" width=\"350\" height=\"350\" alt=\"\">\n",
    "    <figcaption>Original</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"variation.png\" width=\"350\" height=\"350\" alt=\"\">\n",
    "    <figcaption>Variation</figcaption>\n",
    "</figure>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
